I.INTRODUCTION.Bounteous (“Company”) is committed to full compliance with applicable laws related to the use of artificial intelligence in the countries in which the Companyprovides products and services.Additionally, Companyis  committed  to  the  ethical  use  of  artificial  intelligence.This Artificial Intelligence Use Policy (“Policy”) outlines the Company’s requirements with respect to the adoption of all forms of artificial intelligence at Company.Such  artificial  intelligence  adoption  includes  use  for  business  efficiencies,  operations,  and inclusion in Company’s products and services.This Policy is  applicable  to  all Companydirectors,  officers,  board  members,  employees,  contractors, representatives,  affiliates,  agents,  and  any  person  or  entity  performing  services  for  or  on  behalf  of Company.ThePresident of Digital Solutions, Data and AIat Companyis responsible for enforcement of this Policy.II.DEFINITIONS.a.“Approved AI Tool” means AI tools and their particular use cases approved by the AI Committee as set forth on Annex I attached hereto.b.“Artificial  intelligence”  or  “AI”  means  the  use  of  machine  learning  technology,  software, automation, and algorithms, to perform tasks, make rules or predictions, based on existing datasets and instructions.c.“Artificial Intelligence Committee” or “AI Committee” is an internal Companycommittee  tasked with reviewing and approving uses of AI at Company.d.“Artificial intelligence system” or “AI System” means software that is developed with one or more of the techniques and approaches listed in Annex IIand can, for a given set of human-defined objectives, generate  outputs  such  as  content, code, predictions,  recommendations,  or  decisions  influencing  the environments they interact with.e.“Closed AI System” means an AI Systemwhere the input provided by one user is used to train the AI model. Input data from the user is isolated from other users and the data is considered more secure.f.“Embedded AI Tools” means AI tools embedded in existing software tools approved and used at Companyand which do not require approval for use from the AI Committee.g.“Government” means the government of a country or subdivision thereof.h.“Government Entity” means any entity controlled by, in whole or part, a government.This includes Government-owned or controlled (whether whole or partial ownership or control) commercial enterprises, institutions,   agencies,   departments,   instrumentalities,   and   other   public   entities,   including   research institutions and universities.i.“Government Official” means any officer or employee of a Government Entity, an official of a political  party,  a  candidate  for  political office,  officers  and  employees  of  non-governmental international organizations,  and  any  person  with  responsibility  to  allocate  or  influence  expenditures  of  Government 
funds.This includes data scientists and researchers who are employed by a government or a Government Entity. Employees at government organizations are considered Government Officials regardless of title or position. j.“Non-public Companydata” means any information that, if disclosed, could violate the privacy of individuals,  government  regulations  or  statutes,  could  jeopardize  the  financial  state  of Company,  could injure its reputation, or could reduce its competitive advantage.k.“Open AI System” means an AI Systemwhere the input provided by all users is used to train the AI model.Input data from all users is not private and may be revealed to other users.l.“Personal information” means information that identifies, relates to, describes, is capable of being associated with, or could reasonably be linked, directly or indirectly, with a particular person or household. m.“CompanyRepresentatives” means all Companydirectors, officers, board members, employees, contractors,  representatives,  resellers  and  sub-resellers,  distributors  and  sub-distributors,  affiliates, agents, and any person or entity performing services for or on behalf of Company.III.GUIDING PRINCIPLES.The intent of this Policy is to provide general guidance on the use of AI at the Companyso that Companycan  leverage  the  use  of  AI  as  a  tool  while  ensuring  it  continues  to  meet  legal  obligations  and  act  in  an ethical  manner.  The  use  of  AI  at  the Companyshould  never  compromise  the Company’s core values or introduce undue risk to the organization.Rather, the use of AI at Companyshould be focused on improving business efficiencies and enhancing the Company’s ability to fulfill its mission.It is important to remember that the Companyis a global organization.The Companyhas entities and staff globally  and  provides  its  products  and  services  to  customers  globally  as  well.Accordingly,  this  Policy provides  overarching  guidance  based  on  global  standards  for the use  of  AI.CompanyRepresentatives should always considerthe global impact of their decision to use AI, as use of AI that is permitted in some countries may not be permitted in others.This Policy is not intended to address every use of AI at Companyby a CompanyRepresentative.There are  certain  business  departments  and  functions  at  the Companythat  bear  more  considerations  and potential risks.Before using any AI at Company–whether for personal business tasks such as writing an email  or  more  complex  business  processes  such  as  analyzing  datasets -you  should  consult  with  your manager and seek guidance.Also, please see Prohibited Uses in Section IV below for situations in which AI may not be used at the Company, and High-Risk Use of AI Systems in Section VI below for situations in which extreme caution is required when considering using AI.In addition, there are certain Embedded AI Tools used in existing approved Companysoftware that do not require  additional  approval  for  use.For  example,  use  of  Microsoft  Word  in  which  Microsoft  Word  has embedded an AI tool to check spelling or grammar.Use of Embedded AI Tools in approved software tools at Companyis  permitted  provided  the  use  of  those  software  tools  are  aligned  with  previous  general business uses.A list of existing software tools with Embedded AI Tools that are approved at Companycan be foundfrom the AI CoE.
When  third-party  software,  services,  or  contractors are  utilized  or  employed, any  AI  usage  by  software used by these parties or services must be noted and evaluated carefully. Contracted services which utilize AI  technology  should  be  considered  in  the  samelight  as  individual  AI  usage.Consult  with  the  Legal Department about inclusion of an AI-specific clause in any vendor or contractor agreements.The following principles must be followed when considering using an AI Systemat Company:•Use  of  an AI  Systemshould  be  primarily  focused  on  completing  departmental  goals  as  directed  by company  leadership.  Except  for  use  of  an  Embedded  AI  Tool  in  a  software  system  approved  for  use  at Companyor use of an Approved AI Tool, any use of a new AI System at the Companymust be approved by the AI Committee.Additional AI System accessor usage can be requested with an AI Risk Assessment request  made  through  the  AI  Risk  Assessment  form:https://forms.office.com/r/mXE45sjAfd.Also,  see General AI Use Standards and Use Approval in Section IV below.•Individuals using an AI Systemmust have expertise in the subject matter for which the AI is used.AI is to be utilized as a tool and is not a substitute for expertise.For example, if using AI for coding, the individual deploying the AI must have expertise in coding.•All  AI-generated  content  (writing,  datasets,  graphs,  pictures,  etc.)  must  be  thoroughly  reviewed  by  an individual with expertise to evaluate such content for accuracy as well as general proofing and editing.AI-generated  content  should  be  viewed  as  a  starting  point,  not  the  finished  product.Like  any  content  at Company, AI-generated content should conform to the look and feel of the Companybrand and voice.•Any use of an AI Systemmust have clear objectives for the AI use as a tool and business-accepted data sets  from  which  the  AI  draws  upon.If  the  data  sets  that  the  AI  is  using  are  not  accurate,  then  the information AI provides will not be accurate.•AI Systems are trained on data that may contain inherent bias. Users of these systems are responsible to ensure to review any AI produced content for bias and correct it as necessary.•Non-public Companyinformation must never be put into an Open AI System. •Client data, including any client owned or licensed code(or code generated for a client) must never be put into an Open AI System without the express permission and authorization of the relevant client.•Other than specific AI Embedded Tools in an approved existing software tool being used for the intended purpose, CompanyRepresentatives must maintain reasonable records ofall AI Systems they are utilizing and for what functionsso the AI System use can be traced back.Tracking use of AI is not optional and is part  of  your  job.Discuss  with  your  department  head  thepreferred  departmentalprocess  for keeping records ofuse of AI Systems. •Use of an AI Systemmust meet any terms of use or contractual limitations.Contractual restrictions or terms of use may restrict Company’s use of an AI Systemthat would otherwise be legally compliant and ethically sound.For  example,  an AI  System’s terms of use may require use of certain disclaimers in certain use situations or prohibit use of the AI Systemto do certain tasks.CompanyRepresentatives should have all terms or use or  contracts for AI Systems reviewed by the  Legal Department to ensure compliance with contractual obligations in using an AI System.•Approval of an AI Systemdoes not eliminate the need for other internal approvals required at Companyfor  use  of  technology,  such  as  a  security  review,  privacy  review,  cost  review  and  spend  approval,  legal review,  human  resources  review,  etc.An AI  Systemshould  go  through  the  same  review  and  approval process as other software or services at Company.You should also ensure within your business unit that your business leader is aware of the use of the AI Systemand has approved any use of the AI System, particularly for AI-generated content that will be relayed externally.

IV.PROHIBITED USES.There  are  certain uses of AI  which  are prohibited. Unless otherwise  approved by  the  AI committee  and respective department heads, CompanyRepresentatives are prohibited from using AI Systems for any of the following activities at any time: •Using  AI Systems for any clientrelated engagement, including pursuit or  presales collateral, or  artifacts related todelivery, or inputting any client or external party names, data or project information, in any case,that is not expressly authorized by the relevant client.•Conducting political lobbying activities is prohibited. Lobbying is defined as any action aimed at influencing a Government, Government Official or Government Entity for any reason.•Using AI Systems to identify or categorize students, candidates, employees, contractors, or other affiliated entities based on protected class status is prohibited.•Entering trade secrets, confidential information, personal data about any individual into an Open AI System.•Entering  any  sensitive  information  about  any  other  party  or  personinto  any AI  System.“Sensitive information”  includes,  without  limitationmedical,  financial,  political  affiliation,  racial  or  ethnic  origin, religious beliefs, gender, sexual orientation, disability status, or any other part of a person’s life someone would want to keep private.•Using an AI Systemto obtain legal advice, including, but not limited to, creating policies for internal use or to provide to third parties.•Creating  intellectual  property  that  the Companydesires  to  register  and/or  holds  significant  value  to  the organization.V.ETHICAL GUIDELINES.Companydesires to act in an ethical manner when using AI.Accordingly, there may be uses of AI that are legally  permissible,  but  which  do  not  meet  ethical  requirements.Any  use  of  an AI  Systemat Companyshould conform with the following ethical guidelines:•Informed Consent: Prior to inputting personal information into a Closed AI System, ensure that you have obtained informed consent from the individual(s) whose personal information will be inputted.•Integrity in Use:All users of AI Systems should be honest about how AI helped in getting the work done.Even if using an AI Systemapproved by the AI Committee for an approved use, you should ensure your manager or the department requesting a task for which you are using an AI Systemis aware of your use of the AI System.Do not pass off AI-generated work as done by you solely.Additionally, you should ask permission if you desire to use an AI Systemtool to complete a task.For example, you should ask your manager and HR representative if you may use an AISystemto assist in writing a performance evaluation.•Appropriate Content: Do not use company time or resources to generate content using an AI Systemthat would be considered illegal, inappropriate, harmful to Company’s brand or reputation, or disrespectful to others. •Unauthorized Use:Do not use company time or resources to generate content using an AI Systemfor personal use without prior approval of the appropriate department leader.VI.HIGH RISK USE OF AI SYSTEMS.There  are  certain  uses  of AI  Systems  that  are  more  high  risk  than  others.As  a  global  company,  the Companyis committed to complying with all AI legal requirements and guidance in the countries in which
it operates.The European Union (“EU”) has classified the following potential uses of AI as posing a high risk  to  the  health  and  safety  or  fundamental  rights  of  natural  persons.  Therefore,  there  are  several additional requirements for the use of AI Systems in such cases. These requirements are listed in AnnexIII,  withpotentially  applicable  EU  high-risk  system  types  identified  on  Annex  IV  andcertain  functions highlighted below:•Personal Data in AI Systems:AI should be used with extreme caution when inputting any personal data of an individual into a Closed AI System(it is prohibited to put any personal data into an Open AI System). •Screening Job Candidates:AI should be used with caution when screening any job applicants to ensure it is not adversely impacting protected class members or introducing any bias. Equity and inclusion issues surrounding AI use in job screening is a potential source of litigation. •Personnel  Decisions:AI  should  be  used  with  caution  for  any  use  related  to  making  decisions  on promotions,  retention,  or  similar  personnel  such  decisions.  Extreme  caution  should  be  utilized  to  ensure that bias (including biases found in existing data sets) are avoided.•Assessment of Personnel: Any assessment of personnelcapabilities and qualificationsis considered high risk, particularly from a bias-avoidance standpoint.Accordingly extreme caution should be utilized before using any AI Systemintended to assess or evaluate any personnelparticipating in a course, taking an exam, or other evaluation or assessment.VII.GENERAL AI SYSTEM USE STANDARDS AND USE APPROVALExcept for AI Embedded Tools in approved software, all uses of AI Systems must be approved by the AI Committee prior to use to ensure such AI Systemuse meets the following principles:•Lawful:AI Systems use must comply with all applicable laws and regulations, as well as any contractual obligations, limitations, or restrictions.•Ethical:AI Systems use must adhere to ethical principles, be fair, and avoid bias.•Transparent:There must be clear objectives for use of an AI Systemand documented oversight of such use which is recorded and captured for institutional knowledge.Disclosures of the use of AI in any AI-assisted content generation must be made when required by law or contract, or when required by the Company.•Necessary:AI  Systems  use  must  be  for  a  valid  business  purpose  to  improve Company’sbusiness efficiencies and support the organization’s mission.Use of AI is not a substitute for human critical thinking or expertise and should not require Companyto incur an unnecessary expense without any true benefit.•Prior to submitting a request to the AI Committee for use of an AI System, a requester should first obtain the approval of his or her manager.In addition, in evaluating whether to make a request, the requester should ensure that the AI Systemuse, if approved, would conform with the guidelines in this Policy, prior to submitting such request.Additional AI System accessor usage can be requested with an AI Risk Assessment request made through the AI Risk Assessment form:https://forms.office.com/r/mXE45sjAfdVII. REPORTING NON-COMPLIANCE.Companydirectors, managers, employees, and agents aware of any conduct that may violate this Policy have  a  responsibility  to  report  it.  Individuals  are  encouraged  to  make  reports  through  normal  reporting relationships beginning with their manager. All reports ofsuspected misconduct or non-compliance will be investigated by the AI Committee, Legal Counsel, People Team / Human Resources, or other appropriate
parties.Unless  acting  in  bad  faith, Companyemployees  will  not  be  subject  to  reprisals  for  reporting potential violations.If Companydetermines that a CompanyRepresentative has failed to comply with this Policy after an investigation concludes, then the CompanyRepresentative will be subject to disciplinary action, up to and including termination.
ANNEX IAPPROVED AI TOOLS AND USE CASESBelow is the current list of Approved AI Tools, which areapproved ONLY for internal useand which must remain subject to theother terms and conditions of the AI Policy to which this is annexed as well as thespecial conditions and usages requirementsset forth below. AI Tool NameSpecial ConditionsUsage RequirementsReviewed  On -ByGitHub CopilotOnly for use with a license granted underCompany's enterprise planCan only be used for internal projects. For any use for or involving a clientor potential client, such    use    must    beexpresslyapproved  by the  relevant  client.  Access  is prohibited in  case  client  has  not  provided approval explicitly.PendingThe BrainPendingCanonly be used for internal projects. For any use for or involving a client or potential client,    such    use    must    be    expressly approved by the relevant clientPendingOpenAI's APIsSolution must be approved by AI CoEbefore development beginsCanonly be used for internal projects. For any use for or involving a client or potential client,    such    use    must    be    expressly approved by the relevant clientApproved  by  AI CoE case by caseAccoLisaPendingPendingPendingMidjourneyPendingInternal  usageonly  and  only  as  astarting point for graphic design. For any use for or involving  a  client  or  potential  client,  such use  must  be  expressly  approved  by  the relevant clientPendingAdobe FireflyPendingInternal  usageonly  and  only  as  astarting point for graphic design. For any use for or involving  a  client  or  potential  client,  such use  must  be  expressly  approved  by  the relevant clientPendingGONGOnly for use with a license granted under Company's enterprise plan.Access must be granted by AI CoEUse must be disclosed and acknowledged as acceptable by participants at the start of any call.PendingJasper.aiReview  in  Progress, check with AI CoEPendingPendingHeyGenOnly for use with a license granted under Company's enterprise plan.Can only be used for internal projects. For any use for or involving a client or potential client,    such    use    must    be    expressly approved by the relevant client.Pending
ANNEX IIAI TECHNIQUES AND APPROACHESMachine  learning  approaches,  including  supervised,  unsupervised  and  reinforcement  learning,  using  a wide variety of methods including deep learning.Logic   and knowledge-based   approaches,   including   knowledge   representation,   inductive   (logic) programming,  knowledge  bases,  inference,  and  deductive  engines,  (symbolic)  reasoning  and  expert systems.Statistical approaches, Bayesian estimation, search, and optimization methods

ANNEX IIIEU High-Risk System RequirementsCertain requirements apply to high-risk AI Systems as regards the quality of data sets used, technical documentation  and  record-keeping,  transparency,  and  the  provision  of  information  to  users,  human oversight, and robustness, accuracy, and cybersecurity. Thoserequirements are necessary to effectively mitigate the risks for health, safety, and fundamental rights, as applicable in the light of the intended purpose of the system, and no other less trade restrictive measures are available, thus avoiding unjustified restrictions to trade. High  data  quality  is  essential  for  the  performance  of  many AI  Systems,  especially  when  techniques involving the training of models are used, with a view to ensure that the high-risk AI Systemperforms as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation, and testing data sets should be relevant, representative, and free of errors and complete in view of the system's intended purpose. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI Systemis intended to be used. Training, validation, and testing data sets should consider, to the extent required in the light of their intended purpose, the features, characteristics, or elements that are particular to the specific geographical, behavioural, or functional setting or context within which the AI Systemis intended to be used. To protect the right of others from the discrimination that might result from the bias in AI Systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, to ensure the bias monitoring, detection, and correction in relation to high-risk AI Systems.For the development of high-risk AI Systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields ofactivities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will beinstrumental to provide trustful, accountable, and non-discriminatory access to high quality data for the training, validation and testing  of AI  Systems.  For  example,  in  health,  the  European  health  data  space  will  facilitate  non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent, and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing, or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI Systems.Having information on how high-risk AI Systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and technical documentation, containing information necessary to assess the AI System's compliance with the relevant requirements. Such information should include the typical characteristics, capabilities and limitations of the system, algorithms, data, training, testing, and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.
To address the opacity that may make certain AI Systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high-risk AI Systems. Users should be able to interpret the system output and use it appropriately. High-risk AI Systems should therefore be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to risks to fundamental rights and discrimination, where appropriate.High-risk AI Systems should be designed and developed in such a way that natural persons can oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. Where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training, and authority to carry out that role.High-risk AI Systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness, and cybersecurity in accordance with the acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to theusers. Technical robustness is a key requirement for high-risk AI Systems. They should be resilient against risks connected to the limitations of the system (e.g., errors, faults, inconsistencies, unexpected situations) as well as against malicious actions that may compromise the security of the AI Systemand result in harmful or  otherwise undesirable  behavior.  Failure  to  protect  against  these  risks  could  lead  to  safety  impacts or negatively  affect  the  fundamental  rights,  for  example  due  to  erroneous  decisions  or wrong  or  biased outputs generated by the AI System.Cybersecurity plays a crucial role in ensuring that AI Systems are resilient against attempts to alter their use,  behavior,  performance  or  compromise  their  security  properties  by  malicious  third  parties  exploiting the system’s vulnerabilities. Cyberattacks against AI  Systems  can  leverage  AI  specific  assets,  such  as training data sets (e.g., data poisoning) or trained models (e.g., adversarial attacks), or exploit vulnerabilities in  the AI  System’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate  to  the  risks,  suitable  measures  should  therefore  be  taken  by  the  providers  of  high-risk AI Systems, also considering as appropriate the underlying ICT infrastructure.Source :EU Artificial Intelligence Act, para. 43-51
ANNEX IVPotentially Applicable EU High-Risk System Types‘Real-time’ and ‘post’ remote biometric identification systems. Both types should besubject  to  specific requirements on logging capabilities and human oversight.AI Systems used in education or vocational training, notably for determining access or assigning persons to  educational  and  vocational  training  institutions  or  to  evaluate  persons  on  tests  as  part  of  or  as  a precondition for their education.AI  Systems  used  in  employment,  workers  management  and access  to  self-employment,  notably  for  the recruitment  and  selection  of  persons,  for  making  decisions  on  promotion  and  termination  and  for  task allocation, monitoring or evaluation of persons in work-related contractual relationships.Access  to  and  enjoyment  of  certain  essential  private  and  public  services  and  benefitsnecessary forpeopleto fully participate in society or to improve one’s standard of living. AI  Systems  are  used  to evaluate the credit score or creditworthiness of natural persons.Source :EU ArtificialIntelligence Act, para. 33-37
